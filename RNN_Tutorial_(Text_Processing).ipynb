{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1zPAabhrnfMyeowJLhPO1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cerion73/Coursera/blob/main/RNN_Tutorial_(Text_Processing).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1LbVlnl771Nq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "24de0d39-de40-45f1-97cd-e68b9e193ba7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "type object 'DatasetV2' has no attribute 'data_from_directory'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-88e5dab0c930>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mimg_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'images'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mimg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# for image_path in os.listdir(img_dir):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: type object 'DatasetV2' has no attribute 'data_from_directory'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from keras.api.utils import image_dataset_from_directory\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_dir = 'images'\n",
        "img_data = tf.data.Dataset.from_tensor_slices()\n",
        "\n",
        "# for image_path in os.listdir(img_dir):\n",
        "#   img = cv2.imread(os.path.join(img_dir, image_path))\n",
        "#   img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "img_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hrG0OQPv8KJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.expand_dims([[2, 4],[2, 7]], 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIdX29L5ti4X",
        "outputId": "7c49e687-f607-4338-f5a2-f34a93177443"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2, 2), dtype=int32, numpy=\n",
              "array([[[2, 4],\n",
              "        [2, 7]]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"aclImdb_v1\", url,\n",
        "                                    untar=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SmUW7c0tqld",
        "outputId": "25fb2eaa-7d7d-4085-f777-9a446046182e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "\u001b[1m84125825/84125825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-011VoveupqW",
        "outputId": "7c9e50a6-7914-4603-f15d-313c58847041"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./aclImdb'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(os.path.join('aclImdb_v1', dataset_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxNbEg-guyu7",
        "outputId": "56ed917c-c669-4cc3-8b93-a6ff1033118b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test', 'train', 'imdbEr.txt', 'README', 'imdb.vocab']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = 'train'\n",
        "test_dir = 'test'\n",
        "\n",
        "os.listdir(os.path.join('aclImdb_v1', dataset_dir, train_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiclPdCEvASE",
        "outputId": "031fde69-165d-4da2-c776-6c7d788fc7d4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['unsupBow.feat',\n",
              " 'urls_unsup.txt',\n",
              " 'neg',\n",
              " 'labeledBow.feat',\n",
              " 'unsup',\n",
              " 'pos',\n",
              " 'urls_pos.txt',\n",
              " 'urls_neg.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "train_path = os.path.join('aclImdb_v1', dataset_dir, train_dir)\n",
        "test_path = os.path.join('aclImdb_v1', dataset_dir, test_dir)\n",
        "\n",
        "remover_dir = os.path.join(train_path, 'unsup')\n",
        "shutil.rmtree(remover_dir)\n",
        "os.listdir(train_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOgQmAuhvmbF",
        "outputId": "07272492-2026-4455-c895-fa2ce144a8f9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['unsupBow.feat',\n",
              " 'urls_unsup.txt',\n",
              " 'neg',\n",
              " 'labeledBow.feat',\n",
              " 'pos',\n",
              " 'urls_pos.txt',\n",
              " 'urls_neg.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 100\n",
        "batch_size = 32\n",
        "\n",
        "train_ds_raw = tf.keras.utils.text_dataset_from_directory(\n",
        "    train_path,\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "val_ds_raw = tf.keras.utils.text_dataset_from_directory(\n",
        "    train_path,\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "test_ds_raw = tf.keras.utils.text_dataset_from_directory(\n",
        "    train_path,\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWsE-fdLv565",
        "outputId": "82113571-ddc3-42cf-d6ae-6f5793633639"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "\n",
        "def custom_standardizer(input_data):\n",
        "  lower_case = tf.strings.lower(input_data)\n",
        "  stripped_html = tf.strings.regex_replace(lower_case, '<br />', ' ')\n",
        "  return tf.strings.regex_replace(stripped_html,\n",
        "                                  '[%s]' % re.escape(string.punctuation), '')\n",
        "\n",
        "\n",
        "vectorizing_layer = tf.keras.layers.TextVectorization(\n",
        "    standardize=custom_standardizer,\n",
        "    max_tokens=max_features,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=max_features\n",
        ")\n",
        "train_text = train_ds_raw.map(lambda text, labels: text)\n",
        "vectorizing_layer.adapt(train_text)\n",
        "\n",
        "def vectorize_data(data, labels):\n",
        "  text_data = tf.expand_dims(data, -1)\n",
        "  return vectorizing_layer(data), labels\n",
        "\n"
      ],
      "metadata": {
        "id": "9EPOLjs5xCeI"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_b= next(iter(train_ds_raw))\n",
        "train_batch, label_batch = train_b\n",
        "first_review, first_label = train_batch[0], label_batch[0]\n",
        "print(\"Review\", first_review)\n",
        "print(\"Label\", first_label)\n",
        "print(\"Vectorized review: ----\", vectorize_data(first_review, first_label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS-y7Uen3AWH",
        "outputId": "13611ed6-6291-46f0-c356-e7abd3587ae9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review tf.Tensor(b\"My children watch the show everyday that its on. Its a great program for younger children. However they need to stop showing re-runs and do some more actual shows and get rid of Rooney's and Deedee's YELLOW TEETH. Moe is the only Doodle bop with clean white pearlie teeth and the children notice these things and ask if the 2 don't ever brush their teeth? Does the show ever make its way to the United States and if so where can we find its schedule at. And one other thing if we might be able to add. Moe you need to stop hiding so much. Sometimes when you pop up out of no where you scare the younger children and whats with the pulling of the rope? What does that signify? other then getting wet all the time. They need to add newer things to their show instead of the same ole same ole. Kids loose interest that way.\", shape=(), dtype=string)\n",
            "Label tf.Tensor(0, shape=(), dtype=int32)\n",
            "Vectorized review: ---- (<tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
            "array([54,  1,  1,  2,  1,  1, 12, 29, 20, 29,  4, 86,  1, 15,  1,  1,  1,\n",
            "       34,  1,  6,  1,  1,  1,  3, 82, 46, 50,  1,  1,  3, 75,  1,  5,  1,\n",
            "        3,  1,  1,  1,  1,  7,  2, 61,  1,  1, 16,  1,  1,  1,  1,  3,  2,\n",
            "        1,  1,  1,  1,  3,  1, 45,  2,  1, 89,  1,  1, 64,  1,  1,  2,  1,\n",
            "        1, 96, 29, 95,  6,  2,  1,  1,  3, 45, 37,  1, 68, 71,  1, 29,  1,\n",
            "       31,  3, 28, 78,  1, 45, 71,  1, 26,  1,  6,  1,  1, 22,  1])>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds_raw.map(vectorize_data)\n",
        "val_ds = val_ds_raw.map(vectorize_data)\n",
        "test_ds = test_ds_raw.map(vectorize_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "W1twQTdU3GCr"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.api.layers import Embedding, GlobalAveragePooling1D, Dense, Dropout\n",
        "from keras.api. models import Sequential\n",
        "\n",
        "embedding_dim = 16\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(max_features + 1, embedding_dim),\n",
        "    Dropout(0.2),\n",
        "    GlobalAveragePooling1D(),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss=tf.losses.BinaryCrossentropy, optimizer='adam', metrics=[tf.metrics.BinaryAccuracy(threshold=0.5)])\n",
        "\n"
      ],
      "metadata": {
        "id": "OrMCn3CK_jkt"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHoL7vgdAvwT",
        "outputId": "452cd7ff-f48f-4acb-fc34-0e0ff6df388f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - binary_accuracy: 0.6783 - loss: 0.5948 - val_binary_accuracy: 0.6708 - val_loss: 0.5974\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - binary_accuracy: 0.6769 - loss: 0.5948 - val_binary_accuracy: 0.6702 - val_loss: 0.6020\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - binary_accuracy: 0.6763 - loss: 0.5968 - val_binary_accuracy: 0.6716 - val_loss: 0.5975\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - binary_accuracy: 0.6752 - loss: 0.5939 - val_binary_accuracy: 0.6712 - val_loss: 0.5979\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - binary_accuracy: 0.6753 - loss: 0.5954 - val_binary_accuracy: 0.6712 - val_loss: 0.5997\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - binary_accuracy: 0.6766 - loss: 0.5949 - val_binary_accuracy: 0.6736 - val_loss: 0.5977\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - binary_accuracy: 0.6746 - loss: 0.5942 - val_binary_accuracy: 0.6722 - val_loss: 0.5986\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - binary_accuracy: 0.6779 - loss: 0.5947 - val_binary_accuracy: 0.6714 - val_loss: 0.5985\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - binary_accuracy: 0.6755 - loss: 0.5954 - val_binary_accuracy: 0.6708 - val_loss: 0.5976\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - binary_accuracy: 0.6766 - loss: 0.5937 - val_binary_accuracy: 0.6720 - val_loss: 0.6037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "connected_model = tf.keras.Sequential([\n",
        "    vectorizing_layer,\n",
        "    model,\n",
        "    tf.keras.layers.Activation('sigmoid')\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "9WCF2LJZA4X-"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GhDsLuiMBo8o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}